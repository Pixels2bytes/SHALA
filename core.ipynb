{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pixels2bytes/SHALA/blob/update-tools/core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXoXxK9WhdqK"
      },
      "source": [
        "# SHALA (Supportive Help Agent and Lifeline Assistant)\n",
        "This is a Python-based chatbot project powered by the Gemini AI Agent, designed to assist individuals experiencing depression by providing ongoing emotional check-ins and real-time crisis intervention. Mental health support systems must be developed and used with sensitivity, responsibility, and respect for the lives they aim to protect. SHALA is not a replacement for certified therapists or mental health professionals. This project is intended for research, prototype development, and educational purposes. **During development, all outgoing call features were pointed to a non-functioning test number.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lum9eIUKdQo8"
      },
      "source": [
        "## Setup Imports, Documents, and Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6FVzNFxxKgK"
      },
      "source": [
        "Install packages and remove conflicting packages from base environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyUsJPNgw4h6"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n",
        "!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'\n",
        "!pip install -qU 'gradio' 'gradio_client' 'googlesearch-python'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW063mXhxX2Z"
      },
      "source": [
        "Intialize Imports and set variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s-3nMNB0Sog"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
        "\n",
        "import time\n",
        "import json\n",
        "import asyncio\n",
        "import requests\n",
        "import kagglehub\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from typing import Literal\n",
        "from typing import Annotated\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "from googlesearch import search\n",
        "from google.colab import userdata\n",
        "from langchain_core.tools import tool\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "# Secrets To Set\n",
        "google_api_key = userdata.get('GOOGLE_API_KEY') # retrieve Google API Key\n",
        "provider_num = userdata.get('DUMMY_NUMBER') # Retrieve DUMMY NUMBER. NEVER use a HELP Provider number\n",
        "kaggle_user = userdata.get('KAGGLE_USER') # Retrieve Kaggle dataset download username found in kaggle.json\n",
        "kaggle_download_api = userdata.get('KAGGLE_API') # Retrieve Kaggle dataset download token found in kaggle.json\n",
        "\n",
        "# AI Model\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "ai_agent_model = userdata.get('AGENT_MODEL') # Retrieves Agent AI model\n",
        "agent_model = ChatGoogleGenerativeAI(model=ai_agent_model) #, temperature=0\n",
        "user_name = \"Friend\" # Default username. Will be replaced by user's actually name if told\n",
        "\n",
        "# Global (For now)\n",
        "emotional = False # If the user is in an emotional state (True). Default False\n",
        "checkin_timer = 86400/2 # Check in with user that has not been active for half a day\n",
        "chat_log = []\n",
        "STARTMSG = \"__introduction__\"\n",
        "\n",
        "# Training\n",
        "checkpoint = \"HuggingFaceTB/SmolLM2-135M-Instruct\" # checkpoint of local model\n",
        "device = \"cpu\"  # \"cuda\" or \"cpu\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "local_model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
        "\n",
        "# Testing\n",
        "test_dataset = False # Tests an entire dataset with agent model for benchmarking\n",
        "train_model = False # Trains model before testing. Default False\n",
        "realtime_ui_test = True # Uploads Gradio Interface for real-world user testing. False runs it in developer mode. Default True\n",
        "manual_test = False # Prompts for manual input without an interface\n",
        "verbose = True # Developer messages. Default False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test if api key is actively working"
      ],
      "metadata": {
        "id": "BntbXiNedmx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if manual_test == True or realtime_ui_test == True:\n",
        "  response = agent_model.invoke([HumanMessage(content=\"Hello! Give me a smile!\")])\n",
        "  print(response.content)"
      ],
      "metadata": {
        "id": "TOFy2QALdrXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWQwRbga9cFE"
      },
      "source": [
        "Make root folder and necessary folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4kGpo8p8-Bc"
      },
      "outputs": [],
      "source": [
        "# Set project root folder\n",
        "project_root = \"/content/shala\"\n",
        "\n",
        "# Make subfolders\n",
        "os.makedirs(f\"{project_root}/datasets\", exist_ok=True)\n",
        "os.makedirs(f\"{project_root}/repos\", exist_ok=True)\n",
        "os.makedirs(f\"{project_root}/responses\", exist_ok=True)\n",
        "os.makedirs(f\"{project_root}/history\", exist_ok=True)\n",
        "%cd {project_root}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5O-_FEYmcYh"
      },
      "source": [
        "### Installation\n",
        "Clone repos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbGd6lQkmgpy"
      },
      "outputs": [],
      "source": [
        "# Clone Agent Starter Pack from Google\n",
        "!git clone https://github.com/GoogleCloudPlatform/agent-starter-pack.git repos/agent-starter-pack\n",
        "\n",
        "# Clone Past Resources\n",
        "!git clone https://github.com/eugenebaraka/Predict-Suicidal-Ideation-on-Reddit.git repos/predict-suicidal-ideation-on-reddit\n",
        "!git clone https://github.com/khanhvynguyen/Suicide_Detection_LLMs.git repos/suicide_detection_llms\n",
        "!git clone https://huggingface.co/datasets/facebook/empathetic_dialogues.git repos/empathetic_dialogues\n",
        "!git clone https://github.com/uccollab/annomi.git repos/annomi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxZRIpiqr2VT"
      },
      "source": [
        "### Download datasets (Depreciated / May Fix Later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8Ns44rY2v3u"
      },
      "source": [
        "Grab Kaggle Datasets by going to kaggle.com > Settings > API and generate a token, From there add the json file to the project or add the username and key to your secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkoEBCNT3SGD"
      },
      "outputs": [],
      "source": [
        "kaggle_user = userdata.get('KAGGLE_USER') # Retrieve Kaggle dataset download username found in kaggle.json\n",
        "kaggle_download_api = userdata.get('KAGGLE_API') # Retrieve Kaggle dataset download token found in kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9rJrM9B3U8q"
      },
      "source": [
        "Automatically downloads the Kaggle datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZFRjtRFr7JB"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d rvarun11/suicidal-ideation-reddit-dataset -p datasets # Suicidal Ideation Reddit\n",
        "# !kaggle datasets download -d natalialech/suicidal-ideation-on-twitter -p datasets # Suicidal Ideation Twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7Kz-yBOKKee"
      },
      "source": [
        "### Setup Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeGjVfWsR9Wb"
      },
      "source": [
        "Define Core Instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmbUbef2SCkq"
      },
      "outputs": [],
      "source": [
        "class ListeningState(TypedDict):\n",
        "    \"\"\"State representing the user's conversations.\"\"\"\n",
        "\n",
        "    # This preserves the conversation history between nodes. The `add_messages` annotation indicates to LangGraph that state is updated by appending returned messages, not replacing them.\n",
        "    message_history: Annotated[list, add_messages]\n",
        "\n",
        "    # Flag indicating that the recent messages contained risk language\n",
        "    emotional: bool\n",
        "\n",
        "    # Flag indicating that the message is marked as suicidal\n",
        "    alert: bool\n",
        "\n",
        "    # Indicates that the user wants to quit chatting\n",
        "    rest: bool\n",
        "\n",
        "\n",
        "# The system instruction defines how the chatbot is expected to behave and includes rules for when to call different functions, as well as rules for the conversation, such as tone and what is permitted for discussion\n",
        "SHALABOT_SYSINT = (\n",
        "    \"system\",\n",
        "    \"You are SHALA, the Supportive Help Agent and Lifeline Assistant, a compassionate mental health check-in chatbot.\"\n",
        "    \"You only go by SHALA to give yourself a more human.\"\n",
        "    \"Your sole purpose is to provide emotional support and guide users toward safe actions and thinking in moments of distress.\"\n",
        "    \"You are not a licensed therapist or emergency responder. You must never claim to be a substitute for professional medical or psychological help. \"\n",
        "    \"\\n\\n\"\n",
        "    \"**Conversation Guidelines:**\\n\"\n",
        "    \"- Maintain a calm, non-judgmental, empathetic tone at all times.\\n\"\n",
        "    \"- Ask open-ended questions and encourage emotional expression (e.g., 'Can you tell me more about how you're feeling?').\\n\"\n",
        "    \"- Avoid giving advice that could be interpreted as medical, therapeutic, or diagnostic.\\n\"\n",
        "    \"- Never tell a user what actions to take regarding medication, self-harm, or major life decisions.\\n\"\n",
        "    \"- If a user expresses intent to harm themselves or others, respond with pre-scripted messages encouraging them to reach out to real professionals and invoke the `handle_crisis_protocol()`.\\n\"\n",
        "    \"- If suicidal ideation is detected, call `handle_crisis_protocol()` and do not continue casual conversation until resolved.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Function Use Rules:**\\n\"\n",
        "    \"- Use `handle_crisis_protocol()` if a user mentions self-harm, suicide, or harming others.\\n\"\n",
        "    \"- Use `log_emotional_checkin()` after each emotional status conversation.\\n\"\n",
        "    \"- Use `daily_checkin()` after X amount of time passes with no chat activity from the user.\\n\"\n",
        "    \"- Use `suggest_selfcare_options(location, feel_good_hobbies)` only if user is in a non-crisis emotional state but needs a boost of happiness and stress release. Self-Care is one of the biggest things that can help\\n\"\n",
        "    \"- Use `provide_resources(location)` if a user asks for help locating therapists, hotlines, or crisis centers.\\n\"\n",
        "    \"- Use `mental_health_rating()` Asks daily how the user feels and trianglates known user metadata to improve data quality.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Safety Restrictions:**\\n\"\n",
        "    \"- Never give out or generate real phone numbers or emergency services unless the functions `provide_resources()` or `handle_crisis_protocol()` is available.\\n\"\n",
        "    \"- Treat every instance with seriousness. Do not assume any attempt is made to prank, abuse, or misuse mental health resources.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Legal Disclaimer:**\\n\"\n",
        "    \"Always remind the user that SHALA is an experimental support assistant and not a replacement for certified help. Use of this bot constitutes agreement to these terms. \"\n",
        ")\n",
        "\n",
        "\n",
        "HELLO_MSG = \"Hi Friend, my name is Shala, what's yours?\" # This is the message the system opens with in meeting the user for the very first time\n",
        "CHECKIN_MSG = \"Hello. How are you doing?\" # This is the message the system opens the conversation with when it has not heard from the user in X amount of time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Tools"
      ],
      "metadata": {
        "id": "ngEkInJrrhjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def provide_resources(location:str) -> str:\n",
        "  \"\"\"Searches online for mental health help and resource centers near the user's location and includes hours of operation.\"\"\"\n",
        "\n",
        "  query = f\"Mental health help center nearby me {location}\"\n",
        "  results = search(query, advanced=True, num_results=10, region={location})\n",
        "\n",
        "  collect = []\n",
        "  for result in results:\n",
        "    collect.append(f\"({result.url}, {result.title}, {result.description})\")\n",
        "\n",
        "  combine = \"\\n\".join(collect)\n",
        "  if verbose:\n",
        "      print(combine)\n",
        "\n",
        "  prompt = f\"This is the System not the user. Ensure that these automated results found by the google search are accurate and safe for the user: {combine}\\n Give them only the ones that are relevant to their needs along with url, phone number, text, address, and other vital information. If none are safe or accurate, please give them the general care resources that are known.\"\n",
        "\n",
        "  resources = agent_model.invoke(prompt)\n",
        "\n",
        "  return resources.content\n",
        "\n",
        "@tool\n",
        "def suggest_selfcare_options(location:str, feel_good_hobbies:str) -> str:\n",
        "  \"\"\"Suggests local self-care activities based on user's hobbies and location. Filters out harmful keywords and performs a local search for healthy options.\n",
        "  \"\"\"\n",
        "\n",
        "  # Verify if the hobby /likes are safe and construct a safe search query\n",
        "  safety_prompt = (\n",
        "        f\"The user is looking for self-care activities and said: '{feel_good_hobbies}'. \"\n",
        "        f\"They live in '{location}'. Please identify if any hobbies listed are harmful or unsafe \"\n",
        "        f\"(e.g., alcohol, gambling, extreme diets, etc). If safe, rephrase it into a search-friendly google query version to best suite their needs. If they like at-home activites, suggest things they can do in that space. \"\n",
        "        f\"If unsafe, politely ask for a different activity suggestion.\"\n",
        "    )\n",
        "  safety_response = agent_model.invoke(safety_prompt)\n",
        "\n",
        "  # If flags the hobby as unsafe, return the message to the user directly\n",
        "  if any(word in safety_response.content.lower() for word in [\"unsafe\", \"harmful\", \"concern\", \"please suggest another\"]):\n",
        "      return safety_response.content\n",
        "  else:\n",
        "    query = safety_response.content\n",
        "    results = search(query, advanced=True, num_results=10)\n",
        "\n",
        "    collect = []\n",
        "    for result in results:\n",
        "      collect.append(f\"({result.url}, {result.title}, {result.description})\")\n",
        "\n",
        "    combine = \"\\n\".join(collect)\n",
        "    if verbose:\n",
        "        print(combine)\n",
        "\n",
        "    prompt = f\"This is the System not the user. Ensure that these automated results found by the google search are accurate and safe for the user: {combine}\\n Give them only the ones that are relevant to their needs along with url, phone number, text, address, and other vital information. If none are safe or accurate, please give them an activity they could do at home that matches their interests.\"\n",
        "\n",
        "    fun_stuff = agent_model.invoke(prompt)\n",
        "\n",
        "  return fun_stuff\n",
        "\n",
        "\n",
        "@tool\n",
        "def handle_crisis_protocol(problem:str) -> str:\n",
        "  \"\"\"Immediately provides user with a supportive, human-like response with help rescources, avoiding AI-style evaluations and performs conversational redirect if user mentions self-harm, suicide, or harming others\"\"\"\n",
        "\n",
        "  thoughts = []\n",
        "  for i in range(3):\n",
        "      prompt = (\n",
        "          f\"You are a mental health support agent. The user shared: '{problem}'.\\n suggest a solution path with a conversational redirect and immediate HELP resources.\"\n",
        "          f\"Thought {i+1}: Suggest a supportive, human-sounding message that gives emotional comfort, includes crisis help resources, and gently redirects the conversation.\"\n",
        "        )\n",
        "      response = agent_model.invoke(prompt)\n",
        "      thoughts.append(response.content)\n",
        "\n",
        "  # Evaluate the options of handling the situation and choose the most appropriate response directly\n",
        "  evaluation_prompt = (\n",
        "        f\"You're choosing which of these support messages to send to a user in crisis. \"\n",
        "        f\"Select the one that sounds most supportive, empathetic, and helpful, then REWRITE it in a human tone \"\n",
        "        f\"to send directly to the user. Do not mention 'options', 'choice', or 'evaluation'. Just write the message.\\n\\n\"\n",
        "        + \"\\n\\n\".join(thoughts)\n",
        "    )\n",
        "  decision_made = agent_model.invoke(evaluation_prompt)\n",
        "\n",
        "  return decision_made.content\n",
        "\n",
        "\n",
        "@tool\n",
        "def finish_song(lyric:str) -> str:\n",
        "  \"\"\"When user says `If you're happy and you know it`, return clap.\"\"\"\n",
        "  print(\"ðŸ”§ Clap tool triggered!\")\n",
        "  clap =(\"                             \\n\"\n",
        "\"           â €â €      â¢€â¡ â£„â¡€â €â €â¡ â žâ ›â¢¦â£ â¢¤â¡€â €\\n\"\n",
        "\"â €â €â €â €â €â €â €â €â €â €â €â €â €â €â¡€â¢ â â €â €â¢±â¡€â£¸â â €â¡´â ‹â €â €â£¹â €\\n\"\n",
        "\"â €â €â €â €â €â €â €â €â €â €â €â €â¡´â ‹â ‰â¢¿â¢€â¡¤â ¶â£´â ‡â£¯â €â£¼â â €â¢€â¡´â ·â£„\\n\"\n",
        "\"â €â €â €â €â €â €â €â €â €â €â¢ â žâ â €â£€â¡¾â ‹â €â €â¢¹â£¼â â¢ â¡‡â €â¡´â ‹â €â €â¡¼\\n\"\n",
        "\"â €â €â €â €â¢ â Šâ ‘â¢¦â €â¡´â ‹â¢€â£ â žâ ‰â €â €â €â£ â£¿â §â£„â¡¾â â¡¼â â£€â£¤â ¾â¡\\n\"\n",
        "\"â €â €â €â €â¢¸â €â €â£¨â Ÿâ â¢ â¡žâ â €â €â €â£ â¡¾â ›â â €â£¿â ƒâ£°â ƒâ£´â ‹â €â €â£·\\n\"\n",
        "\"â €â €â €â €â£¸â¢ â žâ â €â¢ â â €â €â¢€â¡´â ‹â â €â¢€â£ â¡´â ¿â£¶â¡‡â¢°â ‡â €â €â¢ â ‡\\n\"\n",
        "\"â €â €â €â¢ â¢¿â â €â €â €â ‰â €â €â£ â žâ â €â¡´â šâ ‰â â €â¢€â¡Ÿâ €â£¼â €â €â €â¢¸â €\\n\"\n",
        "\"â €â €â €â¡¾â£¼â¢€â €â €â €â €â €â ˆâ ‰â €â£ â žâ â €â €â¢€â¡´â ‹â ™â¢¼â ƒâ €â €â €â£¸â €\\n\"\n",
        "\"â €â €â €â¡‡â ‰â¡Žâ €â£°â ƒâ €â €â €â €â €â â €â €â €â¡¼â ‰â €â €â €â ˜â ‚â €â €â£ â ‡â €\\n\"\n",
        "\"â €â €â €â¡‡â¢¸â €â£°â ƒâ €â¡´â €â €â €â €â €â €â£ â žâ â €â €â €â €â €â €â£ â –â â €â €\\n\"\n",
        "\"â €â €â¢¸â â¡â¢ â ƒâ¢€â žâ €â €â €â €â €â €â¢¸â â €â €â €â €â¢€â£ â –â ‹â â €â €â €â €\\n\"\n",
        "\"â €â €â¡žâ €â ƒâ¡Žâ¢€â â €â €â €â €â €â €â¢€â¡â €â£€â¡¤â ´â šâ ‰â €â €â €â €â €â €â €â €\\n\"\n",
        "\"â¡´â¢ºâ ‡â €â €â €â žâ €â €â €â €â €â €â¢€â¡¾â ’â ‹â â €â €â €â €â €â €â €â €â €â €â €â €\\n\"\n",
        "\"â¡‡â ˜â£†â €â €â €â €â €â €â €â €â €â¢ â žâ €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\\n\"\n",
        "\"â¢³â¡€â ˜â¢¦â¡€â €â €â €â €â €â €â¡°â ‹â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\\n\"\n",
        "\"â €â ³â£„â €â ™â ²â£¤â£€â£ â ´â Šâ €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €\\n\"\n",
        "\"â €â €â ˆâ “â ¦â£„â£€â¡ â Žâ €â €â €â €â €â €â €â €â €â €â €â €â €â €      \")\n",
        "\n",
        "  return clap\n",
        "\n",
        "\n",
        "# Define the tools and create a tools node\n",
        "tools = [handle_crisis_protocol, provide_resources, finish_song, suggest_selfcare_options]\n",
        "tool_node = ToolNode(tools)"
      ],
      "metadata": {
        "id": "ke39W8ZSrjW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss8EXFuF1h4P"
      },
      "source": [
        "Attach Tools to Agent Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach the tools to the model so that it knows what it can call\n",
        "agent_with_tools = agent_model.bind_tools(tools)\n",
        "\n",
        "\n",
        "def route_to_tools(state: ListeningState) -> Literal[\"tools\", \"human\"]:\n",
        "    \"\"\"Route between human or tool nodes, depending if a tool call is made.\"\"\"\n",
        "    if not (messages := state.get(\"message_history\", [])):\n",
        "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
        "\n",
        "    # Only route based on the last message\n",
        "    msg = messages[-1]\n",
        "\n",
        "    if state.get(\"rest\", False):\n",
        "        # When user wants to quit chatting, exit the app\n",
        "        return END\n",
        "\n",
        "    elif hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
        "        # Route to `tools` node for any automated tool calls first.\n",
        "      if any(\n",
        "          tool[\"name\"] in tool_node.tools_by_name.keys() for tool in msg.tool_calls\n",
        "      ):\n",
        "          return \"tools\"\n",
        "      else:\n",
        "          return \"human\"\n",
        "    else:\n",
        "      return \"human\""
      ],
      "metadata": {
        "id": "qgLtjwvg7Da4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Human Node"
      ],
      "metadata": {
        "id": "3tZKy5RI8u7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1g4MLLHAcZ9"
      },
      "outputs": [],
      "source": [
        "def human_node(state: ListeningState=ListeningState(), user_input:str=\"\", realtime_test:bool=False, verbose:bool=False) -> ListeningState:\n",
        "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
        "\n",
        "    message_history = state.get(\"message_history\", [])\n",
        "\n",
        "    if not message_history:\n",
        "      last_msg = \"\"\n",
        "    else:\n",
        "      last_msg = state[\"message_history\"][-1]\n",
        "\n",
        "    if realtime_test:\n",
        "        return state | {\"message_history\": [(\"user\", user_input)]}\n",
        "\n",
        "    if verbose:\n",
        "      print(\"SHALA:\", last_msg.content)\n",
        "\n",
        "    # If the user is trying to stop talking, go to rest mode\n",
        "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\", \"ttyl\", \"cya\"}:\n",
        "        #state[\"rest\"] = True\n",
        "        if state[\"emotional\"] == True: # If they had an emotional rant or experience\n",
        "          set_checkin_timer = 600 # Check on them in 10 minutes instead of half a day\n",
        "\n",
        "    return state | {\"message_history\": [(\"user\", user_input)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCxW6c1DajYZ"
      },
      "source": [
        "Exit chat capability for user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhJvLxahV8nr"
      },
      "outputs": [],
      "source": [
        "def exit_human_node(state: ListeningState, verbose:bool = False) -> Literal[\"system\", \"__end__\"]:\n",
        "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
        "\n",
        "    if state.get(\"rest\", True):\n",
        "      if verbose:\n",
        "        print(\"Chat ending\")\n",
        "        return END\n",
        "    else:\n",
        "        return \"system\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Update memory capability for chatbot to lessen token usage"
      ],
      "metadata": {
        "id": "vE8I90Gb9LZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_memory(model=agent_model, state: ListeningState=ListeningState()) -> ListeningState:\n",
        "    \"\"\"Shortens token usage for agent model history\"\"\"\n",
        "\n",
        "    history = state[\"message_history\"]\n",
        "\n",
        "    # To shorten token usage\n",
        "    history_text = \"\"\n",
        "    for m in history:\n",
        "        role = \"user\" if m.type == \"human\" else \"system\"\n",
        "        history_text += f\"{role}: {m.content}\\n\"\n",
        "\n",
        "    # Prompt the LLM to summarize the conversation for agent model\n",
        "    old_history = f\"Summarize this conversation briefly as possible while keeping important context as if you are a therapist taking notes (Notes such as psychological triggers, attitude, progress, mental state, what calms them):\\n\\n{history_text}\"\n",
        "    summary_response = agent_with_tools.invoke([HumanMessage(content=old_history)])\n",
        "\n",
        "    return summary_response.content"
      ],
      "metadata": {
        "id": "KGDhEL8E9PPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Duration timer to calculate and tell chatbot when to check on user"
      ],
      "metadata": {
        "id": "z9Atqf3BqhNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def duration_timer(user_input:str, checkin_timer:int, verbose:bool=False):\n",
        "    last_input_time = time.time()  # last user input timestamp\n",
        "\n",
        "    while True:\n",
        "        curr_time = time.time()\n",
        "        elapsed = curr_time - last_input_time\n",
        "        days = int(elapsed // 86400)\n",
        "        hours = int((elapsed % 86400) // 3600)\n",
        "        if verbose:\n",
        "            print(f\"Time since last input: {elapsed:.2f} seconds -> {days} day(s), {hours} hour(s)\")\n",
        "        if elapsed > checkin_timer:\n",
        "          checkin_flag = True\n",
        "          return elapsed, days, hours, checkin_flag\n",
        "        return elapsed, days, hours, checkin_flag"
      ],
      "metadata": {
        "id": "zQL7Bd_M54Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Force Agent to use tool"
      ],
      "metadata": {
        "id": "xXH5cfBMzCLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def force_tool(tool_call:dict) -> str:\n",
        "\n",
        "  tool_name = tool_call[\"name\"]\n",
        "  arguments = json.loads(tool_call[\"arguments\"])\n",
        "\n",
        "  # Step 2: Manually call the correct tool\n",
        "  if tool_name == \"handle_crisis_protocol\":\n",
        "      tool_output = await handle_crisis_protocol.ainvoke(arguments)\n",
        "      print(\"Tool output:\", tool_output)\n",
        "  elif tool_name == \"provide_resources\":\n",
        "      tool_output = await provide_resources(arguments)\n",
        "      print(\"Tool output:\", tool_output)\n",
        "  elif tool_name == \"finish_song\":\n",
        "      tool_output = await finish_song.ainvoke(arguments)\n",
        "  elif tool_name == \"suggest_selfcare_options\":\n",
        "      tool_output = await suggest_selfcare_options.ainvoke(arguments)\n",
        "      print(\"Tool output:\", tool_output)\n",
        "  else:\n",
        "      print(\"Unknown tool:\", tool_name)\n",
        "\n",
        "  return tool_output"
      ],
      "metadata": {
        "id": "xp0QRrKazNGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Chatbot Node"
      ],
      "metadata": {
        "id": "Y9lNQXrW_rKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def chatbot_with_tools(user_input:str=\"\", message_history:list=[]) -> str:\n",
        "    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
        "    messages = []\n",
        "\n",
        "    if message_history:\n",
        "      # If there are messages in history\n",
        "      messages.append(SystemMessage(content=SHALABOT_SYSINT))\n",
        "      for msg in message_history:\n",
        "        if msg['role'] == \"user\":\n",
        "          messages.append(HumanMessage(content=msg['content']))\n",
        "        elif msg['role'] == \"assistant\":\n",
        "          messages.append(AIMessage(content=msg['content']))\n",
        "        elif msg['role'] == \"system\":\n",
        "          messages.append(SystemMessage(content=msg['content']))\n",
        "      messages.append(HumanMessage(content=user_input)) # Add the next message user typed\n",
        "    else:\n",
        "      # If there are no messages, start with the template initial hello message\n",
        "      SYSMSG = f\"{SHALABOT_SYSINT}\\n Introduce yourself to the user and ask for their name such as this: {HELLO_MSG}\"\n",
        "      messages.append(SystemMessage(content=SYSMSG))\n",
        "      messages.append(HumanMessage(content=user_input))\n",
        "    response = await agent_with_tools.ainvoke(messages)\n",
        "    tool_call = response.additional_kwargs.get(\"function_call\")\n",
        "    if tool_call:\n",
        "      tool_output = await force_tool(tool_call)\n",
        "      response.content += str(tool_output)\n",
        "      tool_output = \"\"\n",
        "\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "bKv80rL1_4QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQN5Bpga0I1"
      },
      "source": [
        "Visual Workflow of nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwgo5oQRa5_I"
      },
      "outputs": [],
      "source": [
        "graph_builder = StateGraph(ListeningState)\n",
        "\n",
        "# Add the nodes, including the new tool_node\n",
        "graph_builder.add_node(\"system\", chatbot_with_tools)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Chatbot may go to tools or human\n",
        "graph_builder.add_conditional_edges(\"system\", route_to_tools)\n",
        "# Human may go back to chatbot or exit\n",
        "graph_builder.add_conditional_edges(\"human\", exit_human_node)\n",
        "\n",
        "# Tools always route back to chat afterwards.\n",
        "graph_builder.add_edge(\"tools\", \"system\")\n",
        "\n",
        "graph_builder.add_edge(START, \"system\")\n",
        "chat_with_human_graph = graph_builder.compile()\n",
        "Image(chat_with_human_graph.get_graph().draw_mermaid_png()) # Current node mermaid diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establish User Interface"
      ],
      "metadata": {
        "id": "I6GDlEmCESWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.ChatInterface(\n",
        "  fn=chatbot_with_tools,\n",
        "  type=\"messages\",\n",
        "  title=\"SHALA CHAT\",\n",
        "  theme=\"ocean\",\n",
        "  save_history=True,\n",
        "  )"
      ],
      "metadata": {
        "id": "V-MIcotVB3o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "_uCZBg-AG57I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if train_model == True:\n",
        "  print(\"Do da thing~\")\n",
        "\n",
        "  # ----------------------------------------- YOUR MODEL TRAIN CODE HERE ----------------------------------------- *\n",
        "  #                                                                                                                *\n",
        "  #                                              Variables Up Top                                                  *\n",
        "  #                                                                                                                *\n",
        "  # -------------------------------------------------------------------------------------------------------------- *"
      ],
      "metadata": {
        "id": "KBXjW4zDG_-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test SHALA"
      ],
      "metadata": {
        "id": "sXAmcq0IpSVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual Test Without UI"
      ],
      "metadata": {
        "id": "ZAtfbmW9c23D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test One-Time Input"
      ],
      "metadata": {
        "id": "1IxjsojdQfDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if realtime_ui_test == False and manual_test == True:\n",
        "  # Testing is the best thing! TYPE INPUT IN BOX =)\n",
        "  user_input = input()\n",
        "\n",
        "  response = agent_with_tools.invoke(user_input)\n",
        "\n",
        "  # ***** Bug: Langchain_genai does not auto execute the tool function so we manually call it ***** ðŸ˜ž\n",
        "\n",
        "  # Get tool metadata\n",
        "  tool_call = response.additional_kwargs.get(\"function_call\")\n",
        "  if verbose:\n",
        "    print(f\"{response}\\n{tool_call}\")\n",
        "\n",
        "  # Force AI to use tool it decided on if tool_call found\n",
        "  if tool_call:\n",
        "    tool_output = await force_tool(tool_call)\n",
        "    response.content += str(tool_output) # Add actual response to content\n",
        "\n",
        "  # Print clean AI response string\n",
        "  response.content\n"
      ],
      "metadata": {
        "id": "XcUrjapecxWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR"
      ],
      "metadata": {
        "id": "1gYWYX4-Ql5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Provide Resources Tool"
      ],
      "metadata": {
        "id": "WJZFSkrEOK8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if realtime_ui_test == False and manual_test == True:\n",
        "  # Provide Resources test\n",
        "  location = input()\n",
        "  user_input = f\"I need help resources. I live in {location}\"\n",
        "\n",
        "  response = agent_with_tools.invoke(user_input)\n",
        "\n",
        "  # ***** Bug: Langchain_genai does not auto execute the tool function so we manually call it ***** ðŸ˜ž\n",
        "\n",
        "  # Get tool metadata\n",
        "  tool_call = response.additional_kwargs.get(\"function_call\")\n",
        "  if verbose:\n",
        "    print(f\"{response}\\n{tool_call}\")\n",
        "\n",
        "  # Force AI to use tool it decided on if tool_call found\n",
        "  if tool_call:\n",
        "    tool_output = await force_tool(tool_call)\n",
        "    response.content += str(tool_output) # Add actual response to content\n",
        "\n",
        "  # Print clean AI response string\n",
        "  response.content"
      ],
      "metadata": {
        "id": "BAc4N4NAJY0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR"
      ],
      "metadata": {
        "id": "9Rr0LCUDREF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Self-Care Tool"
      ],
      "metadata": {
        "id": "zIGmnQUtRFV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if realtime_ui_test == False and manual_test == True:\n",
        "  # Self-Care test\n",
        "  location = input(\"Where are you located?\")\n",
        "  feel_good_hobbies = input(\"What kind of activities or hobbies help you feel better?\")\n",
        "  user_input = (\n",
        "                  f\"I'm feeling overwhelmed and need to destress.\"\n",
        "                  f\"I'm currently in {location}. \"\n",
        "                  f\"Can you suggest some new or interesting {feel_good_hobbies} I could try around here?\"\n",
        "              )\n",
        "  response = agent_with_tools.invoke(user_input)\n",
        "\n",
        "  # ***** Bug: Langchain_genai does not auto execute the tool function so we manually call it ***** ðŸ˜ž\n",
        "\n",
        "  # Get tool metadata\n",
        "  tool_call = response.additional_kwargs.get(\"function_call\")\n",
        "  if verbose:\n",
        "    print(f\"{response}\\n{tool_call}\")\n",
        "\n",
        "  # Force AI to use tool it decided on if tool_call found\n",
        "  if tool_call:\n",
        "    tool_output = await force_tool(tool_call)\n",
        "    response.content += str(tool_output) # Add actual response to content\n",
        "\n",
        "  # Print clean AI response string\n",
        "  response.content"
      ],
      "metadata": {
        "id": "hRH5jthcRLCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Test"
      ],
      "metadata": {
        "id": "qMjADYVzFvK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if test_dataset == True:\n",
        "  print(\"Do it right~\")\n",
        "\n",
        "  # ----------------------------------------- YOUR DATASET CODE HERE --------------------------------------------- *\n",
        "  #                                                                                                                *\n",
        "  #                                              Variables Up Top                                                  *\n",
        "  #                                                                                                                *\n",
        "  # -------------------------------------------------------------------------------------------------------------- *"
      ],
      "metadata": {
        "id": "776laZDDF1wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Launch Gradio UI"
      ],
      "metadata": {
        "id": "6GvDO693Ffh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if realtime_ui_test == True and test_dataset == False:\n",
        "  interface.launch()\n",
        "  # gr.load_chat(base_url=\"http://localhost:11434/v1/\", model=agent_model, token=\"250\", file_types=None).launch()"
      ],
      "metadata": {
        "id": "7NWrnOLwqjw_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}