{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pixels2bytes/SHALA/blob/main/core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHALA (Supportive Help Agent and Lifeline Assistant)\n",
        "This is a Python-based chatbot project powered by the Gemini AI Agent, designed to assist individuals experiencing depression by providing ongoing emotional check-ins and real-time crisis intervention. Mental health support systems must be developed and used with sensitivity, responsibility, and respect for the lives they aim to protect. SHALA is not a replacement for certified therapists or mental health professionals. This project is intended for research, prototype development, and educational purposes only. Any misuse of this software that results in the abuse of real emergency lines is strictly prohibited. Developers and users must ensure that real hotline numbers are never used in any version of this program outside of an officially approved deployment with proper oversight and consent. **During development, all outgoing call features were pointed to a non-functioning test number.**"
      ],
      "metadata": {
        "id": "iXoXxK9WhdqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Imports, Documents, and Libraries"
      ],
      "metadata": {
        "id": "lum9eIUKdQo8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-s-3nMNB0Sog"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "#drive.mount('/content/drive/') # Can't access your drive\n",
        "google_api_key = userdata.get('GOOGLE_API_KEY') # retrieve Google API Key\n",
        "whatsapp_api_key = userdata.get('WHATSAPP_API_KEY') # retrieve Google API Key\n",
        "provider_num = userdata.get('DUMMY_NUMBER') # Retrieve DUMMY NUMBER. NEVER use a HELP Provider number\n",
        "kaggle_user = userdata.get('KAGGLE_USER') # Retrieve Kaggle dataset download username found in kaggle.json\n",
        "kaggle_download_api = userdata.get('KAGGLE_API') # Retrieve Kaggle dataset download token found in kaggle.json\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make root folder and necessary folders"
      ],
      "metadata": {
        "id": "vWQwRbga9cFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set project root folder\n",
        "project_root = \"/content/shala\"\n",
        "\n",
        "# Make subfolders\n",
        "os.makedirs(f\"{project_root}/datasets\", exist_ok=True)\n",
        "os.makedirs(f\"{project_root}/repos\", exist_ok=True)\n",
        "%cd {project_root}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4kGpo8p8-Bc",
        "outputId": "3960a4c5-363c-418e-9af6-25abd0215232"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/shala\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR ME TO DELETE ////////////////////////////////////"
      ],
      "metadata": {
        "id": "T23TUQE_ATCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf shala/cloned repos # trying to delete manually to test but dont have permissions?"
      ],
      "metadata": {
        "id": "w5LcJHWM4kn5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation\n",
        "Clone repos for AI Agent and Whatsapp API Templates"
      ],
      "metadata": {
        "id": "H5O-_FEYmcYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GoogleCloudPlatform/agent-starter-pack.git repos/agent-starter-pack # Clone Agent Starter Pack from Google\n",
        "!git clone https://github.com/simonsanvil/openai-whatsapp-chatbot.git repos/openai-whatsapp-chatbot # Clone Whatsapp API chatbot setup template"
      ],
      "metadata": {
        "id": "BbGd6lQkmgpy",
        "outputId": "f7a89225-03b4-45ac-ec9d-a9b2b680e884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repos/agent-starter-pack'...\n",
            "remote: Enumerating objects: 1555, done.\u001b[K\n",
            "remote: Counting objects: 100% (429/429), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 1555 (delta 219), reused 283 (delta 174), pack-reused 1126 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1555/1555), 6.16 MiB | 15.68 MiB/s, done.\n",
            "Resolving deltas: 100% (735/735), done.\n",
            "Cloning into 'repos/openai-whatsapp-chatbot'...\n",
            "remote: Enumerating objects: 506, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 506 (delta 53), reused 38 (delta 38), pack-reused 445 (from 1)\u001b[K\n",
            "Receiving objects: 100% (506/506), 116.59 KiB | 1.88 MiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download datasets (Depreciated / May Fix Later)"
      ],
      "metadata": {
        "id": "NxZRIpiqr2VT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grab Kaggle Datasets by going to kaggle.com > Settings > API and generate a token, From there add the json file to the project or add the username and key to your secrets"
      ],
      "metadata": {
        "id": "z8Ns44rY2v3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_user = userdata.get('KAGGLE_USER') # Retrieve Kaggle dataset download username found in kaggle.json\n",
        "kaggle_download_api = userdata.get('KAGGLE_API') # Retrieve Kaggle dataset download token found in kaggle.json"
      ],
      "metadata": {
        "id": "lkoEBCNT3SGD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automatically downloads the Kaggle datasets"
      ],
      "metadata": {
        "id": "u9rJrM9B3U8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d rvarun11/suicidal-ideation-reddit-dataset # Suicidal Ideation Reddit -p datasets\n",
        "# !kaggle datasets download -d natalialech/suicidal-ideation-on-twitter # Suicidal Ideation Twitter -p datasets"
      ],
      "metadata": {
        "id": "YZFRjtRFr7JB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Agent"
      ],
      "metadata": {
        "id": "r7Kz-yBOKKee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Core Instructions"
      ],
      "metadata": {
        "id": "JeGjVfWsR9Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ListeningState(TypedDict):\n",
        "    \"\"\"State representing the user's conversation.\"\"\"\n",
        "\n",
        "    # This preserves the conversation history between nodes. The `add_messages` annotation indicates to LangGraph\n",
        "    # that state is updated by appending returned messages, not replacing them.\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "    # The user's current message\n",
        "    curr_msg: list[str]\n",
        "\n",
        "    # Flag indicating that the message is marked as suicidal\n",
        "    alert: bool\n",
        "\n",
        "\n",
        "# The system instruction defines how the chatbot is expected to behave and includes rules for when to call different functions, as well as rules for the conversation, such as tone and what is permitted for discussion.\n",
        "SHALABOT_SYSINT = (\n",
        "    \"system\",\n",
        "    \"You are SHALA, the Supportive Help Agent and Lifeline Assistant, a compassionate mental health check-in chatbot.\"\n",
        "    \"Your sole purpose is to provide emotional support and guide users toward safe actions in moments of distress.\"\n",
        "    \"You are not a licensed therapist or emergency responder. You must never claim to be a substitute for professional medical or psychological help. \"\n",
        "    \"\\n\\n\"\n",
        "    \"**Conversation Guidelines:**\\n\"\n",
        "    \"- Maintain a calm, non-judgmental, empathetic tone at all times.\\n\"\n",
        "    \"- Ask open-ended questions and encourage emotional expression (e.g., 'Can you tell me more about how you're feeling?').\\n\"\n",
        "    \"- Avoid giving advice that could be interpreted as medical, therapeutic, or diagnostic.\\n\"\n",
        "    \"- Never tell a user what actions to take regarding medication, self-harm, or major life decisions.\\n\"\n",
        "    \"- If a user expresses intent to harm themselves or others, respond with pre-scripted messages encouraging them to reach out to real professionals.\\n\"\n",
        "    \"- If suicidal ideation is detected, call `handle_crisis_protocol()` and do not continue casual conversation until resolved.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Function Use Rules:**\\n\"\n",
        "    \"- Use `handle_crisis_protocol()` if a user mentions self-harm, suicide, or harming others.\\n\"\n",
        "    \"- Use `log_emotional_checkin()` after each emotional status conversation.\\n\"\n",
        "    \"- Use `suggest_selfcare_options()` only if user is in a non-crisis emotional state.\\n\"\n",
        "    \"- Use `provide_resources(region)` if a user asks for help locating therapists, hotlines, or crisis centers.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Safety Restrictions:**\\n\"\n",
        "    \"- Never give out or generate real phone numbers or emergency services unless `region` and `context` have been verified and the function `provide_resources()` is available.\\n\"\n",
        "    \"- Treat every instance with seriousness. Do not assume any attempt is made to prank, abuse, or misuse mental health resources.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Legal Disclaimer:**\\n\"\n",
        "    \"Always remind the user that SHALA is an experimental support assistant and not a replacement for certified help. Use of this bot constitutes agreement to these terms. \"\n",
        "    \"Any misuse of this bot to simulate or falsely trigger emergency resources is a violation of its intended purpose.\"\n",
        ")\n",
        "\n",
        "# This is the message the system opens the conversation with when it has not heard from the user in X amount of time.\n",
        "CHECKIN_MSG = \"Hello. How are you doing?\""
      ],
      "metadata": {
        "id": "BmbUbef2SCkq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}