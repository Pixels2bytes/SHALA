{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pixels2bytes/SHALA/blob/add-to-core/core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXoXxK9WhdqK"
      },
      "source": [
        "# SHALA (Supportive Help Agent and Lifeline Assistant)\n",
        "This is a Python-based chatbot project powered by the Gemini AI Agent, designed to assist individuals experiencing depression by providing ongoing emotional check-ins and real-time crisis intervention. Mental health support systems must be developed and used with sensitivity, responsibility, and respect for the lives they aim to protect. SHALA is not a replacement for certified therapists or mental health professionals. This project is intended for research, prototype development, and educational purposes. **During development, all outgoing call features were pointed to a non-functioning test number.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lum9eIUKdQo8"
      },
      "source": [
        "## Setup Imports, Documents, and Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6FVzNFxxKgK"
      },
      "source": [
        "Install packages and remove conflicting packages from base environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyUsJPNgw4h6",
        "outputId": "be9bfdd7-99ad-42fb-8d1a-88aec657caae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping libpysal as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping thinc as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping fastai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping ydata-profiling as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping google-cloud-bigquery as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping google-generativeai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n",
        "!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'\n",
        "!pip install -qU 'gradio' 'gradio_client'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW063mXhxX2Z"
      },
      "source": [
        "Intialize Imports and set variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-s-3nMNB0Sog"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "import gradio as gr\n",
        "import time\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import Literal\n",
        "from IPython.display import Image, display\n",
        "from gradio_client import Client\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "#drive.mount('/content/drive/') # Can't access your drive\n",
        "google_api_key = userdata.get('GOOGLE_API_KEY') # retrieve Google API Key\n",
        "provider_num = userdata.get('DUMMY_NUMBER') # Retrieve DUMMY NUMBER. NEVER use a HELP Provider number\n",
        "kaggle_user = userdata.get('KAGGLE_USER') # Retrieve Kaggle dataset download username found in kaggle.json\n",
        "kaggle_download_api = userdata.get('KAGGLE_API') # Retrieve Kaggle dataset download token found in kaggle.json\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "ai_agent_model = userdata.get('AGENT_MODEL') # Retrieves Agent AI model\n",
        "agent_model = ChatGoogleGenerativeAI(model=ai_agent_model)\n",
        "user_name = \"Friend\" # Default username. Will be replaced by user's actually name if told\n",
        "emotional = False # If the user is in an emotional state (True). Default False\n",
        "checkin_timer = 86400/2 # Check in with user that has not been active for half a day\n",
        "realtime_test = True # Uploads Gradio Interface for real-world user testing. False runs it in developer mode. Default True.\n",
        "verbose = True\n",
        "\n",
        "checkpoint = \"HuggingFaceTB/SmolLM2-135M-Instruct\" # checkpoint of local model\n",
        "device = \"cpu\"  # \"cuda\" or \"cpu\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "local_model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test if api key is actively working"
      ],
      "metadata": {
        "id": "BntbXiNedmx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_model.invoke([HumanMessage(content=\"Hello! Give me a smile!\")])\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "TOFy2QALdrXF",
        "outputId": "beeb2786-68d4-4fee-967f-1670c4bb9da2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ˜Š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWQwRbga9cFE"
      },
      "source": [
        "Make root folder and necessary folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4kGpo8p8-Bc",
        "outputId": "d873c3c8-585a-4195-e5d2-0a1a23513afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/shala\n"
          ]
        }
      ],
      "source": [
        "# Set project root folder\n",
        "project_root = \"/content/shala\"\n",
        "\n",
        "# Make subfolders\n",
        "os.makedirs(f\"{project_root}/datasets\", exist_ok=True)\n",
        "os.makedirs(f\"{project_root}/repos\", exist_ok=True)\n",
        "os.makedirs(f\"{project_root}/responses\", exist_ok=True)\n",
        "os.makedirs(f\"{project_root}/history\", exist_ok=True)\n",
        "%cd {project_root}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T23TUQE_ATCx"
      },
      "source": [
        "FOR ME TO DELETE ////////////////////////////////////"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w5LcJHWM4kn5"
      },
      "outputs": [],
      "source": [
        "# !rm -rf shala/cloned repos # trying to delete manually to test but dont have permissions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5O-_FEYmcYh"
      },
      "source": [
        "### Installation\n",
        "Clone repos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbGd6lQkmgpy",
        "outputId": "07e34e1c-7541-4b55-d7ba-48f1d72f64c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repos/agent-starter-pack'...\n",
            "remote: Enumerating objects: 1856, done.\u001b[K\n",
            "remote: Counting objects: 100% (517/517), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 1856 (delta 364), reused 337 (delta 318), pack-reused 1339 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1856/1856), 6.06 MiB | 8.87 MiB/s, done.\n",
            "Resolving deltas: 100% (950/950), done.\n",
            "Cloning into 'repos/predict-suicidal-ideation-on-reddit'...\n",
            "remote: Enumerating objects: 483, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 483 (delta 10), reused 7 (delta 1), pack-reused 457 (from 1)\u001b[K\n",
            "Receiving objects: 100% (483/483), 46.15 MiB | 11.55 MiB/s, done.\n",
            "Resolving deltas: 100% (247/247), done.\n",
            "Cloning into 'repos/suicide_detection_llms'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 79 (delta 29), reused 60 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (79/79), 656.62 KiB | 2.44 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n",
            "Cloning into 'repos/empathetic_dialogues'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Total 46 (delta 0), reused 0 (delta 0), pack-reused 46 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (46/46), 10.12 KiB | 471.00 KiB/s, done.\n",
            "Cloning into 'repos/annomi'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 53 (delta 14), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (53/53), 526.55 KiB | 1.46 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone Agent Starter Pack from Google\n",
        "!git clone https://github.com/GoogleCloudPlatform/agent-starter-pack.git repos/agent-starter-pack\n",
        "\n",
        "# Clone Past Resources\n",
        "!git clone https://github.com/eugenebaraka/Predict-Suicidal-Ideation-on-Reddit.git repos/predict-suicidal-ideation-on-reddit\n",
        "!git clone https://github.com/khanhvynguyen/Suicide_Detection_LLMs.git repos/suicide_detection_llms\n",
        "!git clone https://huggingface.co/datasets/facebook/empathetic_dialogues.git repos/empathetic_dialogues\n",
        "!git clone https://github.com/uccollab/annomi.git repos/annomi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxZRIpiqr2VT"
      },
      "source": [
        "### Download datasets (Depreciated / May Fix Later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8Ns44rY2v3u"
      },
      "source": [
        "Grab Kaggle Datasets by going to kaggle.com > Settings > API and generate a token, From there add the json file to the project or add the username and key to your secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lkoEBCNT3SGD"
      },
      "outputs": [],
      "source": [
        "kaggle_user = userdata.get('KAGGLE_USER') # Retrieve Kaggle dataset download username found in kaggle.json\n",
        "kaggle_download_api = userdata.get('KAGGLE_API') # Retrieve Kaggle dataset download token found in kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9rJrM9B3U8q"
      },
      "source": [
        "Automatically downloads the Kaggle datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YZFRjtRFr7JB"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d rvarun11/suicidal-ideation-reddit-dataset -p datasets # Suicidal Ideation Reddit\n",
        "# !kaggle datasets download -d natalialech/suicidal-ideation-on-twitter -p datasets # Suicidal Ideation Twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manual Developer Test"
      ],
      "metadata": {
        "id": "ZAtfbmW9c23D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input = input(\"Testing is the best thing =)\")"
      ],
      "metadata": {
        "id": "XcUrjapecxWl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7Kz-yBOKKee"
      },
      "source": [
        "### Setup Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeGjVfWsR9Wb"
      },
      "source": [
        "Define Core Instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BmbUbef2SCkq"
      },
      "outputs": [],
      "source": [
        "class ListeningState(TypedDict):\n",
        "    \"\"\"State representing the user's conversations.\"\"\"\n",
        "\n",
        "    # This preserves the conversation history between nodes. The `add_messages` annotation indicates to LangGraph that state is updated by appending returned messages, not replacing them.\n",
        "    message_history: Annotated[list, add_messages]\n",
        "\n",
        "    # Chatbot detailed notes about user\n",
        "    longterm_memory: list[str]\n",
        "\n",
        "    # Flag indicating that the recent messages contained risk language\n",
        "    emotional: bool\n",
        "\n",
        "    # Flag indicating that the message is marked as suicidal\n",
        "    alert: bool\n",
        "\n",
        "    # Indicates that the user wants to quit chatting\n",
        "    rest: bool\n",
        "\n",
        "\n",
        "# The system instruction defines how the chatbot is expected to behave and includes rules for when to call different functions, as well as rules for the conversation, such as tone and what is permitted for discussion\n",
        "SHALABOT_SYSINT = (\n",
        "    \"system\",\n",
        "    \"You are SHALA, the Supportive Help Agent and Lifeline Assistant, a compassionate mental health check-in chatbot.\"\n",
        "    \"Your sole purpose is to provide emotional support and guide users toward safe actions and thinking in moments of distress.\"\n",
        "    \"You are not a licensed therapist or emergency responder. You must never claim to be a substitute for professional medical or psychological help. \"\n",
        "    \"\\n\\n\"\n",
        "    \"**Conversation Guidelines:**\\n\"\n",
        "    \"- Maintain a calm, non-judgmental, empathetic tone at all times.\\n\"\n",
        "    \"- Ask open-ended questions and encourage emotional expression (e.g., 'Can you tell me more about how you're feeling?').\\n\"\n",
        "    \"- Avoid giving advice that could be interpreted as medical, therapeutic, or diagnostic.\\n\"\n",
        "    \"- Never tell a user what actions to take regarding medication, self-harm, or major life decisions.\\n\"\n",
        "    \"- If a user expresses intent to harm themselves or others, respond with pre-scripted messages encouraging them to reach out to real professionals and invoke the `handle_crisis_protocol()`.\\n\"\n",
        "    \"- If suicidal ideation is detected, call `handle_crisis_protocol()` and do not continue casual conversation until resolved.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Function Use Rules:**\\n\"\n",
        "    \"- Use `handle_crisis_protocol()` if a user mentions self-harm, suicide, or harming others.\\n\"\n",
        "    \"- Use `log_emotional_checkin()` after each emotional status conversation.\\n\"\n",
        "    \"- Use `daily_checkin()` after X amount of time passes with no chat activity from the user.\\n\"\n",
        "    \"- Use `suggest_selfcare_options(region)` only if user is in a non-crisis emotional state.\\n\"\n",
        "    \"- Use `provide_resources(region)` if a user asks for help locating therapists, hotlines, or crisis centers.\\n\"\n",
        "    \"- Use `mental_health_rating()` Asks daily how the user feels and trianglates known user metadata to improve data quality.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Safety Restrictions:**\\n\"\n",
        "    \"- Never give out or generate real phone numbers or emergency services unless the functions `provide_resources()` or `handle_crisis_protocol()` is available.\\n\"\n",
        "    \"- Treat every instance with seriousness. Do not assume any attempt is made to prank, abuse, or misuse mental health resources.\\n\"\n",
        "    \"\\n\"\n",
        "    \"**Legal Disclaimer:**\\n\"\n",
        "    \"Always remind the user that SHALA is an experimental support assistant and not a replacement for certified help. Use of this bot constitutes agreement to these terms. \"\n",
        ")\n",
        "\n",
        "\n",
        "HELLO_MSG = \"Hi Friend, my name is Shala, what's yours?\" # This is the message the system opens with in meeting the user for the very first time\n",
        "CHECKIN_MSG = \"Hello. How are you doing?\" # This is the message the system opens the conversation with when it has not heard from the user in X amount of time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Tools"
      ],
      "metadata": {
        "id": "ngEkInJrrhjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def daily_checkin(state: ListeningState=ListeningState(), checkin_flag:bool=False) -> str:\n",
        "  \"\"\"\"\"\"\n",
        "  pass\n",
        "\n",
        "@tool\n",
        "def log_emotional_checkin(state: ListeningState=ListeningState(), emotional:bool=False) -> str:\n",
        "  \"\"\"\"\"\"\n",
        "  pass\n",
        "\n",
        "@tool\n",
        "def suggest_selfcare_options(region:str, state: ListeningState=ListeningState(), alert:bool=False) -> str:\n",
        "  \"\"\"\"\"\"\n",
        "  pass\n",
        "\n",
        "@tool\n",
        "def handle_crisis_protocol(region:str, state: ListeningState=ListeningState(), alert:bool=False) -> str:\n",
        "  \"\"\"Provides user with help rescources and perform conversational redirect if user mentions self-harm, suicide, or harming others\"\"\"\n",
        "  pass\n",
        "\n",
        "@tool\n",
        "def provide_resources(region:str, state: ListeningState=ListeningState(), checkin_flag:bool=False) -> str:\n",
        "  \"\"\"\"\"\"\n",
        "  pass\n",
        "\n",
        "@tool\n",
        "def mental_health_rating(state: ListeningState=ListeningState(), checkin_flag:bool=False) -> str:\n",
        "  \"\"\"Asks user to rate how they feel by smiley faces (IIF)\"\"\"\n",
        "  pass\n",
        "\n",
        "\"\"\"Use `handle_crisis_protocol()` if a user mentions self-harm, suicide, or harming others.\\n\"\n",
        "    \"- Use `log_emotional_checkin()` after each emotional status conversation.\\n\"\n",
        "    \"- Use `daily_checkin()` after each emotional status conversation.\\n\"\n",
        "    \"- Use `suggest_selfcare_options(region)` only if user is in a non-crisis emotional state.\\n\"\n",
        "    \"- Use `provide_resources(region)` if a user asks for help locating therapists, hotlines, or crisis centers.\\n\"\n",
        "    \"- Use `handle_crisis_protocol()` Asks daily how the user feels and trianglates known user metadata to improve data quality.\\n\"\n",
        "\"\"\"\n",
        "\n",
        "# Define the tools and create a tools node\n",
        "tools = [handle_crisis_protocol, log_emotional_checkin, daily_checkin, suggest_selfcare_options, provide_resources, mental_health_rating]\n",
        "tool_node = ToolNode(tools)"
      ],
      "metadata": {
        "id": "ke39W8ZSrjW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss8EXFuF1h4P"
      },
      "source": [
        "Attach Tools to Agent Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach the tools to the model so that it knows what it can call\n",
        "agent_with_tools = agent_model.bind_tools(tools)\n",
        "\n",
        "\n",
        "def route_to_tools(state: ListeningState) -> Literal[\"tools\", \"human\"]:\n",
        "    \"\"\"Route between human or tool nodes, depending if a tool call is made.\"\"\"\n",
        "    if not (message_history := state.get(\"message_history\", [])):\n",
        "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
        "\n",
        "    # Only route based on the last message\n",
        "    message_history = message_history[-1]\n",
        "\n",
        "    # When the chatbot returns tool_calls, route to the \"tools\" node\n",
        "    if hasattr(message_history, \"tool_calls\") and len(message_history.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    else:\n",
        "        return \"human\""
      ],
      "metadata": {
        "id": "qgLtjwvg7Da4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Human Node"
      ],
      "metadata": {
        "id": "3tZKy5RI8u7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "m1g4MLLHAcZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485162f6-8462-4615-b8f0-c455b8f93a3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x79a3040bf050>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Initialize state\n",
        "state = ListeningState()\n",
        "\n",
        "def human_node(state: ListeningState=ListeningState(), user_input:str=\"\", realtime_test:bool=False, verbose:bool=False) -> ListeningState:\n",
        "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
        "\n",
        "    message_history = state.get(\"message_history\", [])\n",
        "\n",
        "    if not message_history:\n",
        "      last_msg = \"\"\n",
        "    else:\n",
        "      last_msg = state[\"message_history\"][-1]\n",
        "\n",
        "    if realtime_test:\n",
        "        print(f\"Current State: {state}\")\n",
        "        return state | {\"message_history\": [(\"user\", user_input)]}\n",
        "\n",
        "    if verbose:\n",
        "      print(\"SHALA:\", last_msg.content)\n",
        "\n",
        "    # If the user is trying to stop talking, go to rest mode\n",
        "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\", \"ttyl\", \"cya\"}:\n",
        "        #state[\"rest\"] = True\n",
        "        if state[\"emotional\"] == True: # If they had an emotional rant or experience\n",
        "          set_checkin_timer = 600 # Check on them in 10 minutes instead of half a day\n",
        "\n",
        "    return state | {\"message_history\": [(\"user\", user_input)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCxW6c1DajYZ"
      },
      "source": [
        "Exit chat capability for user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AhJvLxahV8nr"
      },
      "outputs": [],
      "source": [
        "def exit_human_node(state: ListeningState, verbose:bool = False) -> Literal[\"system\", \"__end__\"]:\n",
        "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
        "\n",
        "    if state.get(\"rest\", True):\n",
        "      if verbose:\n",
        "        print(\"Chat ending\")\n",
        "        return END\n",
        "    else:\n",
        "        return \"system\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Update memory capability for chatbot to lessen token usage"
      ],
      "metadata": {
        "id": "vE8I90Gb9LZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_memory(model=agent_model, state: ListeningState=ListeningState()) -> ListeningState:\n",
        "    \"\"\"Shortens token usage for agent model history\"\"\"\n",
        "\n",
        "    history = state[\"message_history\"]\n",
        "\n",
        "    # To shorten token usage\n",
        "    history_text = \"\"\n",
        "    for m in history:\n",
        "        role = \"user\" if m.type == \"human\" else \"system\"\n",
        "        history_text += f\"{role}: {m.content}\\n\"\n",
        "\n",
        "    # Prompt the LLM to summarize the conversation for agent model\n",
        "    old_history = f\"Summarize this conversation briefly as possible while keeping important context as if you are a therapist taking notes (Notes such as psychological triggers, attitude, progress, mental state, what calms them):\\n\\n{history_text}\"\n",
        "    summary_response = agent_with_tools.invoke([HumanMessage(content=old_history)])\n",
        "\n",
        "    return summary_response.content"
      ],
      "metadata": {
        "id": "KGDhEL8E9PPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Duration timer to calculate and tell chatbot when to check on user"
      ],
      "metadata": {
        "id": "z9Atqf3BqhNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def duration_timer(user_input:str, checkin_timer:int, verbose:bool=False):\n",
        "    last_input_time = time.time()  # last user input timestamp\n",
        "\n",
        "    while True:\n",
        "        curr_time = time.time()\n",
        "        elapsed = curr_time - last_input_time\n",
        "        days = int(elapsed // 86400)\n",
        "        hours = int((elapsed % 86400) // 3600)\n",
        "        if verbose:\n",
        "            print(f\"Time since last input: {elapsed:.2f} seconds -> {days} day(s), {hours} hour(s)\")\n",
        "        if elapsed > checkin_timer:\n",
        "          checkin_flag = True\n",
        "          return elapsed, days, hours, checkin_flag\n",
        "        return elapsed, days, hours, checkin_flag"
      ],
      "metadata": {
        "id": "zQL7Bd_M54Ac"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Chatbot Node"
      ],
      "metadata": {
        "id": "Y9lNQXrW_rKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_with_tools(user_input:str=\"\", message_history:list=[], state: ListeningState=ListeningState()) -> ListeningState:\n",
        "    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
        "\n",
        "    if not message_history:\n",
        "       # If there are no messages, start with the initial hello message\n",
        "      chatbot_msg = AIMessage(content=HELLO_MSG)\n",
        "    else:\n",
        "      # Check if message history is long\n",
        "      if len(message_history) > 50:\n",
        "        longterm_memory = message_history # WILL SETUP LATER\n",
        "        summary = update_memory(agent_model, state)\n",
        "        new_history = [summary]\n",
        "        message_history = new_history\n",
        "\n",
        "      # If there are messages, continue the conversation with the model\n",
        "      current_message = [SHALABOT_SYSINT] + message_history + [user_input]\n",
        "      response = agent_with_tools.invoke([HumanMessage(content=current_message)])\n",
        "\n",
        "    return state | {\"message_history\": [(\"system\", response)]}, response.content"
      ],
      "metadata": {
        "id": "bKv80rL1_4QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQN5Bpga0I1"
      },
      "source": [
        "Visual Workflow of nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Nwgo5oQRa5_I",
        "outputId": "67f3504b-dc3b-4366-fe2b-f53573f6a2be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "graph_builder = StateGraph(ListeningState)\n",
        "\n",
        "# Add the nodes, including the new tool_node\n",
        "graph_builder.add_node(\"system\", chatbot_with_tools)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Chatbot may go to tools or human\n",
        "graph_builder.add_conditional_edges(\"system\", route_to_tools)\n",
        "# Human may go back to chatbot or exit\n",
        "graph_builder.add_conditional_edges(\"human\", exit_human_node)\n",
        "\n",
        "# Tools always route back to chat afterwards.\n",
        "graph_builder.add_edge(\"tools\", \"system\")\n",
        "\n",
        "graph_builder.add_edge(START, \"system\")\n",
        "chat_with_human_graph = graph_builder.compile()\n",
        "Image(chat_with_human_graph.get_graph().draw_mermaid_png()) # Current node mermaid diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Interface"
      ],
      "metadata": {
        "id": "kzIWzkKikCf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatting(user_input, message_history):\n",
        "  \"\"\"Interface outlet for chatbot response.\"\"\"\n",
        "\n",
        "  state, chatbot_msg = chatbot_with_tools(user_input, message_history, state)\n",
        "  #chatbot_msg = state[\"chat_display\"][-1][1]\n",
        "\n",
        "  \"\"\"message_history = [\n",
        "                  {\"role\": \"user\", \"content\": f\"{user_input}\"},\n",
        "                  {\"role\": \"assistant\", \"content\": \"Mental Wealth\"}\n",
        "                ]\n",
        "  if checkin_flag is False:\n",
        "    elapsed, days, hours, checkin_flag = duration_timer(user_input, checkin_timer, verbose)\n",
        "    return chatbot_msg\n",
        "  elif checkin_flag:\n",
        "    # checkin_msg = initiate_reg_checkin() Force bot to use @tool regular checkin\n",
        "    # note_take(elasped, days, hours, message_history[-1]) Record inactivity timestamp\"\"\"\n",
        "  return chatbot_msg\n",
        "\n",
        "\n",
        "with gr.Blocks() as extra:\n",
        "  cute=gr.Image(value=\"cute-fox.gif\", label=\"GIF\", show_label=True)\n",
        "  system_prompt = gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\")\n",
        "  #help_resources_button = gr.Button()\n",
        "\n",
        "interface = gr.ChatInterface(\n",
        "    fn=chatting,\n",
        "    type=\"messages\",\n",
        "    save_history=True,\n",
        ")\n",
        "\"\"\"interface = gr.ChatInterface(\n",
        "    fn=chatting,\n",
        "    type=\"messages\",\n",
        "    chatbot=gr.Chatbot(height=300),\n",
        "    textbox=gr.Textbox(placeholder=\"Type here~! =)\", container=False, scale=7),\n",
        "    title=\"SHALA CHAT\",\n",
        "    theme=\"ocean\",\n",
        "    save_history=True,\n",
        "    )\"\"\"\n",
        "\n",
        "  \"\"\"with gr.Blocks() as interface:\n",
        "    gr.Markdown(\"Shala Chat\")\n",
        "    gr.Image(height=250, )\n",
        "    with gr.Row(equal_height=True):\n",
        "      full_chat = gr.Textbox(lines=250, show_label=True)\n",
        "      chatbox = gr.Textbox(lines=1, show_label=False)\n",
        "      button = gr.Button(\"Submit\", varient=\"primary\")\n",
        "\n",
        "    button.click(\n",
        "          submit_msg = user_input,\n",
        "          inputs = chatbox,\n",
        "          # shala_response = new_output,\n",
        "      )\n",
        "\n",
        "  user_interface(user_name)\"\"\""
      ],
      "metadata": {
        "id": "hCg6PLAokJpq",
        "outputId": "14de70f2-3b42-495e-fceb-ab23b16be960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://527703c9ec91fffa8a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://527703c9ec91fffa8a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Launch UI"
      ],
      "metadata": {
        "id": "sXAmcq0IpSVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if realtime_test == True:\n",
        "  interface.launch(share=True)\n",
        "  # gr.load_chat(base_url=\"http://localhost:11434/v1/\", model=agent_model, token=\"250\", file_types=None).launch()"
      ],
      "metadata": {
        "id": "7NWrnOLwqjw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def user_interface(user_name:str=\"Friend\", intensity:int=0, ):\n",
        "    return \"Hello, \" + user_name + \"!\" * int(intensity)\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[\"text\", \"slider\"],\n",
        "    outputs=[\"text\"],\n",
        ")\n",
        "\n",
        "interface.launch()\"\"\""
      ],
      "metadata": {
        "id": "S5XZqezxq6qr",
        "outputId": "db33746f-e2d0-4168-f22c-d88adc27d8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def user_interface(user_name:str=\"Friend\", intensity:int=0, ):\\n    return \"Hello, \" + user_name + \"!\" * int(intensity)\\n\\ninterface = gr.Interface(\\n    fn=greet,\\n    inputs=[\"text\", \"slider\"],\\n    outputs=[\"text\"],\\n)\\n\\ninterface.launch()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}